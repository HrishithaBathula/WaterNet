digraph {
	graph [size="38.85,38.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2235183442560 [label="
 (1, 3, 256, 256)" fillcolor=darkolivegreen1]
	2235235194512 [label=AddBackward0]
	2235235193936 -> 2235235194512
	2235235193936 [label=AddBackward0]
	2235235194368 -> 2235235193936
	2235235194368 [label=MulBackward0]
	2235235194224 -> 2235235194368
	2235235194224 [label=SliceBackward0]
	2235235194560 -> 2235235194224
	2235235194560 [label=SliceBackward0]
	2235235194128 -> 2235235194560
	2235235194128 [label=SoftmaxBackward0]
	2235235194656 -> 2235235194128
	2235235194656 [label=ConvolutionBackward0]
	2235235194752 -> 2235235194656
	2235235194752 [label=ReluBackward0]
	2235235194944 -> 2235235194752
	2235235194944 [label=ConvolutionBackward0]
	2235235195040 -> 2235235194944
	2235235195040 [label=ReluBackward0]
	2235235195232 -> 2235235195040
	2235235195232 [label=ConvolutionBackward0]
	2235235195328 -> 2235235195232
	2235235195328 [label=ReluBackward0]
	2235235195520 -> 2235235195328
	2235235195520 [label=ConvolutionBackward0]
	2235235195616 -> 2235235195520
	2235235195616 [label=ReluBackward0]
	2235235195808 -> 2235235195616
	2235235195808 [label=ConvolutionBackward0]
	2235235195904 -> 2235235195808
	2235235195904 [label=ReluBackward0]
	2235235196096 -> 2235235195904
	2235235196096 [label=ConvolutionBackward0]
	2235235196192 -> 2235235196096
	2235235196192 [label=ReluBackward0]
	2235235196384 -> 2235235196192
	2235235196384 [label=ConvolutionBackward0]
	2235235196480 -> 2235235196384
	2235235196480 [label=ReluBackward0]
	2235235196672 -> 2235235196480
	2235235196672 [label=ConvolutionBackward0]
	2235235196768 -> 2235235196672
	2235183426816 [label="conf_map.model.0.weight
 (128, 12, 7, 7)" fillcolor=lightblue]
	2235183426816 -> 2235235196768
	2235235196768 [label=AccumulateGrad]
	2235235196720 -> 2235235196672
	2235183426736 [label="conf_map.model.0.bias
 (128)" fillcolor=lightblue]
	2235183426736 -> 2235235196720
	2235235196720 [label=AccumulateGrad]
	2235235196432 -> 2235235196384
	2235183426576 [label="conf_map.model.2.weight
 (128, 128, 5, 5)" fillcolor=lightblue]
	2235183426576 -> 2235235196432
	2235235196432 [label=AccumulateGrad]
	2235235196288 -> 2235235196384
	2235183426496 [label="conf_map.model.2.bias
 (128)" fillcolor=lightblue]
	2235183426496 -> 2235235196288
	2235235196288 [label=AccumulateGrad]
	2235235196144 -> 2235235196096
	2235183425936 [label="conf_map.model.4.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2235183425936 -> 2235235196144
	2235235196144 [label=AccumulateGrad]
	2235235196000 -> 2235235196096
	2235183425856 [label="conf_map.model.4.bias
 (128)" fillcolor=lightblue]
	2235183425856 -> 2235235196000
	2235235196000 [label=AccumulateGrad]
	2235235195856 -> 2235235195808
	2235183425696 [label="conf_map.model.6.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2235183425696 -> 2235235195856
	2235235195856 [label=AccumulateGrad]
	2235235195712 -> 2235235195808
	2235183425616 [label="conf_map.model.6.bias
 (64)" fillcolor=lightblue]
	2235183425616 -> 2235235195712
	2235235195712 [label=AccumulateGrad]
	2235235195568 -> 2235235195520
	2235183425456 [label="conf_map.model.8.weight
 (64, 64, 7, 7)" fillcolor=lightblue]
	2235183425456 -> 2235235195568
	2235235195568 [label=AccumulateGrad]
	2235235195424 -> 2235235195520
	2235183425376 [label="conf_map.model.8.bias
 (64)" fillcolor=lightblue]
	2235183425376 -> 2235235195424
	2235235195424 [label=AccumulateGrad]
	2235235195280 -> 2235235195232
	2235183415456 [label="conf_map.model.10.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	2235183415456 -> 2235235195280
	2235235195280 [label=AccumulateGrad]
	2235235195136 -> 2235235195232
	2235183415616 [label="conf_map.model.10.bias
 (64)" fillcolor=lightblue]
	2235183415616 -> 2235235195136
	2235235195136 [label=AccumulateGrad]
	2235235194992 -> 2235235194944
	2235183426416 [label="conf_map.model.12.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2235183426416 -> 2235235194992
	2235235194992 [label=AccumulateGrad]
	2235235194848 -> 2235235194944
	2235183426336 [label="conf_map.model.12.bias
 (64)" fillcolor=lightblue]
	2235183426336 -> 2235235194848
	2235235194848 [label=AccumulateGrad]
	2235235194704 -> 2235235194656
	2235183422096 [label="conf_map.model.14.weight
 (3, 64, 3, 3)" fillcolor=lightblue]
	2235183422096 -> 2235235194704
	2235235194704 [label=AccumulateGrad]
	2235235194080 -> 2235235194656
	2235183422016 [label="conf_map.model.14.bias
 (3)" fillcolor=lightblue]
	2235183422016 -> 2235235194080
	2235235194080 [label=AccumulateGrad]
	2235235194032 -> 2235235194368
	2235235194032 [label=ConvolutionBackward0]
	2235235194416 -> 2235235194032
	2235235194416 [label=ReluBackward0]
	2235235194896 -> 2235235194416
	2235235194896 [label=ConvolutionBackward0]
	2235235195664 -> 2235235194896
	2235235195664 [label=ReluBackward0]
	2235235196240 -> 2235235195664
	2235235196240 [label=ConvolutionBackward0]
	2235235196528 -> 2235235196240
	2235235196528 [label=ReluBackward0]
	2235235196864 -> 2235235196528
	2235235196864 [label=ConvolutionBackward0]
	2235235196912 -> 2235235196864
	2235183427376 [label="ftu_gc.model.0.weight
 (32, 3, 7, 7)" fillcolor=lightblue]
	2235183427376 -> 2235235196912
	2235235196912 [label=AccumulateGrad]
	2235235196816 -> 2235235196864
	2235183427296 [label="ftu_gc.model.0.bias
 (32)" fillcolor=lightblue]
	2235183427296 -> 2235235196816
	2235235196816 [label=AccumulateGrad]
	2235235196048 -> 2235235196240
	2235183417296 [label="ftu_gc.model.2.weight
 (32, 32, 5, 5)" fillcolor=lightblue]
	2235183417296 -> 2235235196048
	2235235196048 [label=AccumulateGrad]
	2235235195952 -> 2235235196240
	2235183417216 [label="ftu_gc.model.2.bias
 (32)" fillcolor=lightblue]
	2235183417216 -> 2235235195952
	2235235195952 [label=AccumulateGrad]
	2235235195184 -> 2235235194896
	2235183416976 [label="ftu_gc.model.4.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2235183416976 -> 2235235195184
	2235235195184 [label=AccumulateGrad]
	2235235195088 -> 2235235194896
	2235183416816 [label="ftu_gc.model.4.bias
 (32)" fillcolor=lightblue]
	2235183416816 -> 2235235195088
	2235235195088 [label=AccumulateGrad]
	2235235194464 -> 2235235194032
	2235183427216 [label="ftu_gc.model.6.weight
 (3, 32, 1, 1)" fillcolor=lightblue]
	2235183427216 -> 2235235194464
	2235235194464 [label=AccumulateGrad]
	2235235194608 -> 2235235194032
	2235183427136 [label="ftu_gc.model.6.bias
 (3)" fillcolor=lightblue]
	2235183427136 -> 2235235194608
	2235235194608 [label=AccumulateGrad]
	2235235193888 -> 2235235193936
	2235235193888 [label=MulBackward0]
	2235235195472 -> 2235235193888
	2235235195472 [label=SliceBackward0]
	2235235195760 -> 2235235195472
	2235235195760 [label=SliceBackward0]
	2235235194128 -> 2235235195760
	2235235194800 -> 2235235193888
	2235235194800 [label=ConvolutionBackward0]
	2235235196576 -> 2235235194800
	2235235196576 [label=ReluBackward0]
	2235235196960 -> 2235235196576
	2235235196960 [label=ConvolutionBackward0]
	2235235197152 -> 2235235196960
	2235235197152 [label=ReluBackward0]
	2235235197344 -> 2235235197152
	2235235197344 [label=ConvolutionBackward0]
	2235235197440 -> 2235235197344
	2235235197440 [label=ReluBackward0]
	2235235197632 -> 2235235197440
	2235235197632 [label=ConvolutionBackward0]
	2235235197728 -> 2235235197632
	2235183428336 [label="ftu_he.model.0.weight
 (32, 3, 7, 7)" fillcolor=lightblue]
	2235183428336 -> 2235235197728
	2235235197728 [label=AccumulateGrad]
	2235235197680 -> 2235235197632
	2235183428256 [label="ftu_he.model.0.bias
 (32)" fillcolor=lightblue]
	2235183428256 -> 2235235197680
	2235235197680 [label=AccumulateGrad]
	2235235197392 -> 2235235197344
	2235183428096 [label="ftu_he.model.2.weight
 (32, 32, 5, 5)" fillcolor=lightblue]
	2235183428096 -> 2235235197392
	2235235197392 [label=AccumulateGrad]
	2235235197248 -> 2235235197344
	2235183428016 [label="ftu_he.model.2.bias
 (32)" fillcolor=lightblue]
	2235183428016 -> 2235235197248
	2235235197248 [label=AccumulateGrad]
	2235235197104 -> 2235235196960
	2235183427856 [label="ftu_he.model.4.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2235183427856 -> 2235235197104
	2235235197104 [label=AccumulateGrad]
	2235235197008 -> 2235235196960
	2235183427776 [label="ftu_he.model.4.bias
 (32)" fillcolor=lightblue]
	2235183427776 -> 2235235197008
	2235235197008 [label=AccumulateGrad]
	2235235196624 -> 2235235194800
	2235183427616 [label="ftu_he.model.6.weight
 (3, 32, 1, 1)" fillcolor=lightblue]
	2235183427616 -> 2235235196624
	2235235196624 [label=AccumulateGrad]
	2235235195376 -> 2235235194800
	2235183427536 [label="ftu_he.model.6.bias
 (3)" fillcolor=lightblue]
	2235183427536 -> 2235235195376
	2235235195376 [label=AccumulateGrad]
	2235235194176 -> 2235235194512
	2235235194176 [label=MulBackward0]
	2235235196336 -> 2235235194176
	2235235196336 [label=SliceBackward0]
	2235235197056 -> 2235235196336
	2235235197056 [label=SliceBackward0]
	2235235194128 -> 2235235197056
	2235235194320 -> 2235235194176
	2235235194320 [label=ConvolutionBackward0]
	2235235197296 -> 2235235194320
	2235235197296 [label=ReluBackward0]
	2235235197872 -> 2235235197296
	2235235197872 [label=ConvolutionBackward0]
	2235235197920 -> 2235235197872
	2235235197920 [label=ReluBackward0]
	2235235198112 -> 2235235197920
	2235235198112 [label=ConvolutionBackward0]
	2235235198208 -> 2235235198112
	2235235198208 [label=ReluBackward0]
	2235235198400 -> 2235235198208
	2235235198400 [label=ConvolutionBackward0]
	2235235198496 -> 2235235198400
	2235183429296 [label="ftu_wb.model.0.weight
 (32, 3, 7, 7)" fillcolor=lightblue]
	2235183429296 -> 2235235198496
	2235235198496 [label=AccumulateGrad]
	2235235198448 -> 2235235198400
	2235183420416 [label="ftu_wb.model.0.bias
 (32)" fillcolor=lightblue]
	2235183420416 -> 2235235198448
	2235235198448 [label=AccumulateGrad]
	2235235198160 -> 2235235198112
	2235183429216 [label="ftu_wb.model.2.weight
 (32, 32, 5, 5)" fillcolor=lightblue]
	2235183429216 -> 2235235198160
	2235235198160 [label=AccumulateGrad]
	2235235198016 -> 2235235198112
	2235183429136 [label="ftu_wb.model.2.bias
 (32)" fillcolor=lightblue]
	2235183429136 -> 2235235198016
	2235235198016 [label=AccumulateGrad]
	2235235197776 -> 2235235197872
	2235183428816 [label="ftu_wb.model.4.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2235183428816 -> 2235235197776
	2235235197776 [label=AccumulateGrad]
	2235235197584 -> 2235235197872
	2235183428736 [label="ftu_wb.model.4.bias
 (32)" fillcolor=lightblue]
	2235183428736 -> 2235235197584
	2235235197584 [label=AccumulateGrad]
	2235235197536 -> 2235235194320
	2235183428576 [label="ftu_wb.model.6.weight
 (3, 32, 1, 1)" fillcolor=lightblue]
	2235183428576 -> 2235235197536
	2235235197536 [label=AccumulateGrad]
	2235235197488 -> 2235235194320
	2235183428496 [label="ftu_wb.model.6.bias
 (3)" fillcolor=lightblue]
	2235183428496 -> 2235235197488
	2235235197488 [label=AccumulateGrad]
	2235235194512 -> 2235183442560
}
